import os

import torch
from torch.autograd import Variable


def dynamic_import(path):
    components = path.split('.')
    mod = __import__(components[0])
    for comp in components[1:]:
        mod = getattr(mod, comp)
    return mod


def recursive_to_cpu(value):
    """
    Shallow copy here for lists.

    :param value:
    :return:
    """
    if isinstance(value, torch.Tensor):
        # most features generated by network is gpu tensor
        # print('value is tensor')
        return value.cpu().detach()
    elif isinstance(value, list):
        # if is list of gpu tensor
        # print('value is list')
        for i in range(len(value)):
            value[i] = recursive_to_cpu(value[i])
    elif isinstance(value, tuple):
        value = list(value)
        for i in range(len(value)):
            value[i] = recursive_to_cpu(value[i])
    return value


def recursive_wrap_data(data, output_device):
    """
    recursively wrap tensors in data into Variable and move to device.

    :param data:
    :return:
    """
    if output_device == 'cpu':
        return data
    if isinstance(data, list):
        for i in range(len(data)):
            data[i] = recursive_wrap_data(data[i], output_device)
    elif isinstance(data, torch.Tensor):
        return Variable(data.cuda(output_device), requires_grad=False)
    return data


def change_ext(path: str, ext: str):
    """
    Changes ext in filename specified by path.
    ext should be like '.xxx' or 'xxx' in '.xxx'.
    """
    if not ext.startswith('.'):
        ext = '.' + ext
    return os.path.splitext(path)[0] + ext
